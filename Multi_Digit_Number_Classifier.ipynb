{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhoL2RwEJJIFDFppXZbX/U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FFyNOGw9YJp"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "random.seed(101)\n",
        "\n",
        "# Function to build synthetic data\n",
        "def build_synth_data(data, labels, dataset_size):\n",
        "    synth_img_height = 224\n",
        "    synth_img_width = 224\n",
        "\n",
        "    synth_data = []\n",
        "    synth_labels = []\n",
        "\n",
        "    for i in range(dataset_size):\n",
        "        num_digits = random.randint(1, 5)\n",
        "        synth_indices = [random.randint(0, len(data)-1) for p in range(num_digits)]\n",
        "        new_small_image = np.hstack([data[index] for index in synth_indices])\n",
        "\n",
        "        starting_left = random.randint(1, synth_img_width-(num_digits*28))\n",
        "        starting_bottom = random.randint(28, synth_img_height-1)\n",
        "        starting_right = starting_left + num_digits*28\n",
        "        starting_top = starting_bottom - 28\n",
        "\n",
        "        new_label = [starting_left, starting_top, starting_right, starting_bottom]\n",
        "\n",
        "        left_zeros = np.empty(shape=[28, starting_left])\n",
        "        right_zeros = np.empty(shape=[28, synth_img_width - starting_left - (28*num_digits)])\n",
        "        bottom_zeros = np.empty(shape=[synth_img_height-starting_bottom, synth_img_height])\n",
        "        top_zeros = np.empty(shape=[starting_top, synth_img_height])\n",
        "\n",
        "        new_image = np.hstack([left_zeros, new_small_image])\n",
        "        new_image = np.hstack([new_image, right_zeros])\n",
        "        new_image = np.vstack([new_image, bottom_zeros])\n",
        "        new_image = np.vstack([top_zeros, new_image])\n",
        "\n",
        "        synth_data.append(new_image)\n",
        "        synth_labels.append(new_label)\n",
        "\n",
        "    return synth_data, synth_labels\n",
        "\n",
        "# Function to prepare data for Keras\n",
        "def prep_data_keras(img_data):\n",
        "    synth_img_height = 224\n",
        "    synth_img_width = 224\n",
        "\n",
        "    # Handle NaNs/Infs and ensure data is clipped between 0 and 255\n",
        "    img_data = np.nan_to_num(img_data, nan=0.0, posinf=255.0, neginf=0.0)\n",
        "    img_data = np.clip(img_data, 0, 255)\n",
        "\n",
        "    # Normalize the images\n",
        "    img1 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img2 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img3 = np.array(img_data, dtype=\"float32\") / 255.0\n",
        "    img_data = np.concatenate((img1, img2, img3), axis=2)\n",
        "    img_data = img_data.reshape(len(img_data), synth_img_height, synth_img_width, 3)\n",
        "\n",
        "    return img_data\n",
        "\n",
        "def convert_labels(labels):\n",
        "    targets = np.array(labels, dtype=\"float32\")\n",
        "    return targets\n",
        "\n",
        "# Load MNIST data\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_synth_train, y_synth_train = build_synth_data(X_train, y_train, 60)\n",
        "X_synth_test, y_synth_test = build_synth_data(X_test, y_test, 10)\n",
        "\n",
        "train_labels = convert_labels(y_synth_train)\n",
        "test_labels = convert_labels(y_synth_test)\n",
        "\n",
        "train_images = prep_data_keras(X_synth_train)\n",
        "test_images = prep_data_keras(X_synth_test)\n",
        "\n",
        "# Manually split data into training and validation sets\n",
        "train_images_split, val_images_split, train_labels_split, val_labels_split = train_test_split(train_images, train_labels, test_size=0.1)\n",
        "\n",
        "# Data Augmentation using Keras ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create separate generators for training and validation\n",
        "train_generator = datagen.flow(train_images_split, train_labels_split, batch_size=16)\n",
        "val_generator = datagen.flow(val_images_split, val_labels_split, batch_size=16)\n",
        "\n",
        "# Load VGG16 for bounding box prediction\n",
        "vgg = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_tensor=tf.keras.Input(shape=(224, 224, 3)))\n",
        "vgg.trainable = False\n",
        "\n",
        "# Bounding box regression model\n",
        "flatten = vgg.output\n",
        "flatten = tf.keras.layers.Flatten()(flatten)\n",
        "bboxHead = tf.keras.layers.Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dropout(0.3)(bboxHead)  # Add dropout\n",
        "bboxHead = tf.keras.layers.Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dropout(0.3)(bboxHead)  # Add dropout\n",
        "bboxHead = tf.keras.layers.Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "model = tf.keras.models.Model(inputs=vgg.input, outputs=bboxHead)\n",
        "\n",
        "# Adjust steps_per_epoch and validation_steps\n",
        "steps_per_epoch = len(train_images_split) // 16\n",
        "validation_steps = len(val_images_split) // 16\n",
        "\n",
        "# Compile and train the model\n",
        "INIT_LR = 5e-5  # Lowered from 1e-4\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, min_lr=1e-6)\n",
        "\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=validation_steps,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping, lr_reduction])\n",
        "\n",
        "# Extract digits from bounding boxes\n",
        "def extract_digits_from_bbox(images, bboxes):\n",
        "    digits = []\n",
        "    for img, bbox in zip(images, bboxes):\n",
        "        x1, y1, x2, y2 = bbox\n",
        "\n",
        "        # Ensure the coordinates are within the image bounds\n",
        "        x1 = max(0, int(x1))\n",
        "        y1 = max(0, int(y1))\n",
        "        x2 = min(img.shape[1], int(x2))\n",
        "        y2 = min(img.shape[0], int(y2))\n",
        "\n",
        "        # Ensure the bounding box is valid (non-zero area)\n",
        "        if x2 > x1 and y2 > y1:\n",
        "            digit_img = img[y1:y2, x1:x2]\n",
        "            digit_img = tf.image.resize(digit_img, (28, 28))\n",
        "            digits.append(digit_img)\n",
        "        else:\n",
        "            # Handle the case where the bounding box is invalid\n",
        "            # You could append a placeholder or skip this digit\n",
        "            print(f\"Invalid bounding box: {bbox}, skipping...\")\n",
        "            digits.append(np.zeros((28, 28, 3)))  # Placeholder for invalid bboxes\n",
        "\n",
        "    return np.array(digits)\n",
        "\n",
        "\n",
        "# Create CNN+RNN model for digit classification\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed\n",
        "\n",
        "cnn_rnn_model = Sequential()\n",
        "cnn_rnn_model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=(5, 28, 28, 3)))\n",
        "cnn_rnn_model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), padding='same')))\n",
        "cnn_rnn_model.add(Dropout(0.3))  # Add dropout\n",
        "cnn_rnn_model.add(TimeDistributed(Flatten()))\n",
        "cnn_rnn_model.add(LSTM(50, return_sequences=True))\n",
        "cnn_rnn_model.add(Dropout(0.3))  # Add dropout\n",
        "cnn_rnn_model.add(TimeDistributed(Dense(10, activation='softmax')))\n",
        "\n",
        "cnn_rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_rnn_model.summary()\n",
        "\n",
        "# After training bounding box model, predict and extract digits\n",
        "# After training bounding box model, predict and extract digits\n",
        "predicted_bboxes = model.predict(test_images)\n",
        "digit_images = extract_digits_from_bbox(test_images, predicted_bboxes)\n",
        "\n",
        "# Count valid digit images\n",
        "num_valid_digits = len([img for img in digit_images if img is not None])\n",
        "\n",
        "# Ensure we have enough digits and corresponding labels\n",
        "expected_digits_per_image = 5\n",
        "\n",
        "if num_valid_digits < expected_digits_per_image:\n",
        "    print(f\"Not enough valid digits extracted: {num_valid_digits}\")\n",
        "else:\n",
        "    # Calculate the number of full sets of digits\n",
        "    num_full_sets = num_valid_digits // expected_digits_per_image\n",
        "    total_digits_needed = num_full_sets * expected_digits_per_image\n",
        "\n",
        "    # Select only the valid digit images\n",
        "    digit_images = np.array([img for img in digit_images if img is not None][:total_digits_needed])\n",
        "\n",
        "    # Corresponding labels should match the number of valid digit images\n",
        "    digit_labels = to_categorical(y_test[:total_digits_needed], 10).reshape((num_full_sets, expected_digits_per_image, 10))\n",
        "\n",
        "    # Train CNN+RNN model on the extracted digits\n",
        "    H = cnn_rnn_model.fit(digit_images, digit_labels, validation_split=0.1, epochs=5, verbose=1)\n",
        "\n",
        "    # Save the trained model\n",
        "    cnn_rnn_model.save(\"cnn_rnn_model.h5\", save_format=\"h5\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_score = cnn_rnn_model.evaluate(digit_images, digit_labels, verbose=0)\n",
        "    print(f\"Test Loss: {test_score[0]}, Test Accuracy: {test_score[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "ajpkBhPKXTV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set the number of epochs\n",
        "N = len(H.history['loss'])\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"CNN+RNN Model Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hU4NKC6w9mAO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}